{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "# from gensim.models import Word2Vec\n",
    "from random import choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_G = nx.read_gml('./Graphs/corpus_vocab.gml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkLM():\n",
    "    def __init__(self, G, freq = 'freq', count = 'count') -> None:\n",
    "        \"\"\"Initialise the language model\n",
    "        Parameters:\n",
    "            G (nx.DiGraph): the vocabulary network\n",
    "            freq (str): the node attribute that stores word frequency (default: freq)\n",
    "            count (str): the edge attribute that stores edge frequency (default: count)\n",
    "        Returns:\n",
    "            None\"\"\"\n",
    "        \n",
    "        self.G = G\n",
    "        self.freq = freq\n",
    "        self.count = count\n",
    "        self.SENT_BEG = '<s>'\n",
    "        self.SENT_END = '</s>'\n",
    "        \n",
    "    def k_most_common_from(self, target, k = 10) -> dict:\n",
    "        \"\"\"Find the k most common words after a target word\n",
    "        Parameters:\n",
    "            target (str): the target word\n",
    "            k (int): the limit (default: 10), if None then all are retrieved\n",
    "        Returns:\n",
    "            dict: next words and their probabilities sorted desc\"\"\"\n",
    "        \n",
    "        # find all possible next words and counts using out-edges of target\n",
    "        next_words = {i[1]: i[2][self.count] for i in self.G.out_edges(target, data = True)}\n",
    "        \n",
    "        if len(next_words) > 0:\n",
    "            total = sum(next_words.values())  # calculate total out-edges\n",
    "            \n",
    "            # get next words sorted desc by probability\n",
    "            next_words = sorted({i: next_words[i] / total for i in next_words}.items(), key = lambda x: x[1], reverse = True)\n",
    "            \n",
    "            if k:\n",
    "                return dict(next_words[: k])\n",
    "            else:\n",
    "                return dict(next_words)\n",
    "            \n",
    "        return dict()\n",
    "    \n",
    "    def k_most_common_to(self, target, k = 10) -> dict:\n",
    "        \"\"\"Find the k most common words before a target word\n",
    "        Parameters:\n",
    "            target (str): the target word\n",
    "            k (int): the limit (default: 10), if None then all are retrieved\n",
    "        Returns:\n",
    "            dict: prev words and their probabilities sorted desc\"\"\"\n",
    "        \n",
    "        # find all possible prev words and counts using in-edges of target\n",
    "        prev_words = {i[0]: i[2][self.count] for i in self.G.in_edges(target, data = True)}\n",
    "        \n",
    "        if len(prev_words) > 0:\n",
    "            total = sum(prev_words.values())  # calculate total in-edges\n",
    "            \n",
    "            # get prev words sorted desc by probability\n",
    "            prev_words = sorted({i: prev_words[i] / total for i in prev_words}.items(), key = lambda x: x[1], reverse = True)\n",
    "            \n",
    "            if k:\n",
    "                return dict(prev_words[: k])\n",
    "            else:\n",
    "                return dict(prev_words)\n",
    "            \n",
    "        return dict()\n",
    "    \n",
    "    def perplexity(self, prob, n) -> float:\n",
    "        \"\"\"Calculate the perplexity given the probability\n",
    "        Parameters:\n",
    "            prob (float): the probability\n",
    "            n (int): sentence length\n",
    "        Returns:\n",
    "            float: the perplexity\"\"\"\n",
    "    \n",
    "        return prob ** (-1 / n)\n",
    "    \n",
    "    def generate_sentence_shannon(self, seed, max_len = 10, mode = 1) -> (list, float):\n",
    "        \"\"\"Generate a sentence from a seed word\n",
    "        Parameters:\n",
    "            seed (str): the seed word\n",
    "            max_len (int): the max sentence length (default: 10)\n",
    "            mode (int): mode of operation - 1 uses out-edges, 0 uses in-edges (default: 1)\n",
    "        Returns:\n",
    "            list: the tokens of the generated sentence\n",
    "            float: the sentence probability\"\"\"\n",
    "        \n",
    "        score = 0\n",
    "        sentence, sent_len = [], 0 if seed == self.SENT_BEG else 1\n",
    "        \n",
    "        sentence.append(seed)  # append the seed to the empty sentence\n",
    "        \n",
    "        # generate the next words\n",
    "        while sent_len <= max_len:\n",
    "            words = None\n",
    "            \n",
    "            if mode == 1:  # get possible words using out edges\n",
    "                words = self.k_most_common_from(sentence[-1], k = None)\n",
    "            else:\n",
    "                words = self.k_most_common_to(sentence[-1], k = None)\n",
    "                \n",
    "            if len(words) == 0:\n",
    "                break\n",
    "            \n",
    "            # select word and add to sentence\n",
    "            word = choices(list(words.keys()), list(words.values()))\n",
    "            word = word[0]\n",
    "            \n",
    "            sentence.append(word)\n",
    "            sent_len += 1\n",
    "            \n",
    "            score += np.log10(words[word])  # get probability of the selected word \n",
    "            \n",
    "            # break conditions\n",
    "            if mode == 1 and word == self.SENT_END:\n",
    "                break\n",
    "            elif mode == 0 and word == self.SENT_BEG:\n",
    "                break\n",
    "                \n",
    "        if mode == 1:\n",
    "            if sentence[-1] != self.SENT_END:\n",
    "                sentence.append(self.SENT_END)\n",
    "\n",
    "            if sentence[0] != self.SENT_BEG:\n",
    "                sentence.insert(0, self.SENT_BEG)\n",
    "                \n",
    "        else:\n",
    "            if sentence[-1] != self.SENT_BEG:\n",
    "                sentence.append(self.SENT_BEG)\n",
    "                \n",
    "            if sentence[0] != self.SENT_END:\n",
    "                sentence.insert(0, self.SENT_END)\n",
    "                \n",
    "        return sentence, 10 ** score\n",
    "    \n",
    "    def generate_sentence_inside_out(self, seed, before = 5, after = 4) -> (str, float):\n",
    "        \"\"\"Generate a sentence inside-out\n",
    "        Parameters:\n",
    "            seed (str): the seed word\n",
    "            before (int): the number of words require before the seed (default: 5)\n",
    "            after (int): the number of sentences required after the seed (default: 4)\n",
    "        Returns:\n",
    "            list: the tokens of the generated sentence\n",
    "            float: the sentence probability\"\"\"\n",
    "        \n",
    "        sentence_before, prob_before = self.generate_sentence_shannon(seed, before, mode = 0)\n",
    "        \n",
    "        sentence_after, prob_after = self.generate_sentence_shannon(seed, after)\n",
    "        \n",
    "        sentence_before = sentence_before[:: -1][: -1]  # reverse the list and remove the last token i.e. </s>\n",
    "        sentence_after = sentence_after[2 :]  # remove the first 2 tokens i.e. <s> and the seed\n",
    "        \n",
    "        sentence_before.extend(sentence_after)\n",
    "        \n",
    "        total_score = np.log10(prob_before) + np.log10(prob_after)  # get total score\n",
    "        \n",
    "        return sentence_before, 10 ** total_score\n",
    "        \n",
    "    def generate_sentences(self, seed, technique = 1, n = 5, max_len = 10, before = 5, after = 4) -> (list, list):\n",
    "        \"\"\"Generate n sentences\n",
    "        Parameters:\n",
    "            technique\n",
    "            seend (str): the seed word\n",
    "            technique (int): whether to use standard shannon (1) or inside-out (2) (default: 1)\n",
    "            n (int): the number of sentences to generate (default: 5)\n",
    "            max_len (int): the max sentence length if using standard shannon (default: 10)\n",
    "            before (int): the number of words require before the seed if using inside-out (default:  5)\n",
    "            after (int): the number of sentences required after the seed if using inside-out (default: 4)\n",
    "        Returns:\n",
    "            list: a list of sentences\n",
    "            list: a list of associated probabilities\"\"\"\n",
    "        \n",
    "        sentences, probs = [], []\n",
    "        \n",
    "        if technique == 1:\n",
    "            for _ in range(n):\n",
    "                sentence, prob = self.generate_sentence_shannon(seed, max_len = max_len)\n",
    "                \n",
    "                sentences.append(' '.join(sentence))\n",
    "                probs.append(prob)\n",
    "                \n",
    "        elif technique == 2:\n",
    "            for _ in range(n):\n",
    "                sentence, prob = self.generate_sentence_inside_out(seed, before = before, after = after)\n",
    "                \n",
    "                sentences.append(' '.join(sentence))\n",
    "                probs.append(prob)\n",
    "                \n",
    "        return sentences, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlm = NetworkLM(vocab_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s> smart wonder to the detective s bay of six miles that </s>',\n",
       " '<s> smart hundred steps from sir francis </s>',\n",
       " '<s> smart revelation and breathing was the thick weighs 1 500 lb </s>',\n",
       " '<s> smart wager the brightness with a bad fortune favors the frigate </s>',\n",
       " '<s> smart breath at 5 600 atmospheres </s>']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents, probs = nlm.generate_sentences('smart', technique = 1)\n",
    "\n",
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s> sir scorched his hand my dear phileas fogg who denies you going on to the fire was the frigate have made all kinds heaped up to dig a candidate for a bag as they will be placed near his command the lashings like a meeting a chimerical creature your opinion and yet </s>',\n",
       " '<s> say that slid to be to phileas fogg betrayed the nautilus </s>',\n",
       " '<s> phileas fogg snugly ensconced himself to mr fogg </s>',\n",
       " '<s> protector and a sly dog said mr fogg like perambulating pagodas tigers wanting and the coal </s>',\n",
       " '<s> this region through phileas fogg applied to lose a word of silence </s>']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents, probs = nlm.generate_sentences('fogg', technique = 2, before = 7, after = 100)\n",
    "\n",
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s, p = nlm.generate_sentences('nemo', technique = 1)\n",
    "# pp = []\n",
    "\n",
    "# for i in range(len(s)):\n",
    "#     pp.append(nlm.perplexity(p[i], len(s[i])))\n",
    "    \n",
    "# s, p, pp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
