{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "from random import choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_G = nx.read_gml('./Graphs/corpus_vocab.gml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkLM():\n",
    "#     def __init__(self, graph_path, freq = 'freq', count = 'count') -> None:\n",
    "    def __init__(self, G, freq = 'freq', count = 'count') -> None:\n",
    "        \"\"\"Initialise the language model\n",
    "        Parameters:\n",
    "            graph_path (str): filepath to the network GML\n",
    "            freq (str): the node attribute that stores word frequency (default: freq)\n",
    "            count (str): the edge attribute that stores edge frequency (default: count)\n",
    "        Returns:\n",
    "            None\"\"\"\n",
    "        \n",
    "#         self.G = nx.read_gml(graph_path)\n",
    "        self.G = G\n",
    "        self.freq = freq\n",
    "        self.count = count\n",
    "        self.SENT_BEG = '<s>'\n",
    "        self.SENT_END = '</s>'\n",
    "        \n",
    "    def k_most_common_from(self, target, k = 10) -> dict:\n",
    "        \"\"\"Find the k most common words after a target word\n",
    "        Parameters:\n",
    "            target (str): the target word\n",
    "            k (int): the limit (default: 10), if None then all are retrieved\n",
    "        Returns:\n",
    "            dict: next words and their probabilities sorted desc\"\"\"\n",
    "        \n",
    "        # find all possible next words and counts using out-edges of target\n",
    "        next_words = {i[1]: i[2][self.count] for i in self.G.out_edges(target, data = True)}\n",
    "        \n",
    "        if len(next_words) > 0:\n",
    "            total = sum(next_words.values())  # calculate total out-edges\n",
    "            \n",
    "            # get next words sorted desc by probability\n",
    "            next_words = sorted({i: next_words[i] / total for i in next_words}.items(), key = lambda x: x[1], reverse = True)\n",
    "            \n",
    "            if k:\n",
    "                return dict(next_words[: k])\n",
    "            else:\n",
    "                return dict(next_words)\n",
    "            \n",
    "        return dict()\n",
    "    \n",
    "    def k_most_common_to(self, target, k = 10) -> dict:\n",
    "        \"\"\"Find the k most common words before a target word\n",
    "        Parameters:\n",
    "            target (str): the target word\n",
    "            k (int): the limit (default: 10), if None then all are retrieved\n",
    "        Returns:\n",
    "            dict: prev words and their probabilities sorted desc\"\"\"\n",
    "        \n",
    "        # find all possible prev words and counts using in-edges of target\n",
    "        prev_words = {i[0]: i[2][self.count] for i in self.G.in_edges(target, data = True)}\n",
    "        \n",
    "        if len(prev_words) > 0:\n",
    "            total = sum(prev_words.values())  # calculate total in-edges\n",
    "            \n",
    "            # get prev words sorted desc by probability\n",
    "            prev_words = sorted({i: prev_words[i] / total for i in prev_words}.items(), key = lambda x: x[1], reverse = True)\n",
    "            \n",
    "            if k:\n",
    "                return dict(prev_words[: k])\n",
    "            else:\n",
    "                return dict(prev_words)\n",
    "            \n",
    "        return dict()\n",
    "    \n",
    "    def perplexity(self, prob, n) -> float:\n",
    "        \"\"\"Calculate the perplexity given the probability\n",
    "        Parameters:\n",
    "            prob (float): the probability\n",
    "        Returns:\n",
    "            float: the perplexity\"\"\"\n",
    "    \n",
    "        return prob ** (-1 / n)\n",
    "    \n",
    "    def generate_sentence_shannon(self, seed, max_len = 10, mode = 1) -> (list, float):\n",
    "        \"\"\"Generate a sentence from a seed word\n",
    "        Parameters:\n",
    "            seed (str): the seed word\n",
    "            max_len (int): the max sentence length (default: 10)\n",
    "            mode (int): mode of operation - 1 uses out-edges, 0 uses in-edges (default: 1)\n",
    "        Returns:\n",
    "            list: the tokens of the generated sentence\n",
    "            float: the sentence probability\"\"\"\n",
    "        \n",
    "        score = 0\n",
    "        sentence, sent_len = [], 0 if seed == self.SENT_BEG else 1\n",
    "        \n",
    "        sentence.append(seed)  # append the seed to the empty sentence\n",
    "        \n",
    "        # generate the next words\n",
    "        while sent_len <= max_len:\n",
    "            words = None\n",
    "            \n",
    "            if mode == 1:  # get possible words using out edges\n",
    "                words = self.k_most_common_from(sentence[-1], k = None)\n",
    "            else:\n",
    "                words = self.k_most_common_to(sentence[-1], k = None)\n",
    "                \n",
    "            if len(words) == 0:\n",
    "                break\n",
    "            \n",
    "            # select word and add to sentence\n",
    "            word = choices(list(words.keys()), list(words.values()))\n",
    "            word = word[0]\n",
    "            \n",
    "            sentence.append(word)\n",
    "            sent_len += 1\n",
    "            \n",
    "            score += np.log10(words[word])  # get probability of the selected word \n",
    "            \n",
    "            # break conditions\n",
    "            if mode == 1 and word == self.SENT_END:\n",
    "                break\n",
    "            elif mode == 0 and word == self.SENT_BEG:\n",
    "                break\n",
    "                \n",
    "        if mode == 1:\n",
    "            if sentence[-1] != self.SENT_END:\n",
    "                sentence.append(self.SENT_END)\n",
    "\n",
    "            if sentence[0] != self.SENT_BEG:\n",
    "                sentence.insert(0, self.SENT_BEG)\n",
    "                \n",
    "        else:\n",
    "            if sentence[-1] != self.SENT_BEG:\n",
    "                sentence.append(self.SENT_BEG)\n",
    "                \n",
    "            if sentence[0] != self.SENT_END:\n",
    "                sentence.insert(0, self.SENT_END)\n",
    "                \n",
    "        return sentence, 10 ** score\n",
    "    \n",
    "    def generate_sentence_inside_out(self, seed, before = 5, after = 4) -> (str, float):\n",
    "        \"\"\"\"\"\"\n",
    "        \n",
    "        sb, p = self.generate_sentence_shannon(seed, before, mode = 0)\n",
    "        \n",
    "        sa, p = self.generate_sentence_shannon(seed, after)\n",
    "        \n",
    "        print(' '.join(sb[:: -1]))\n",
    "        print(' '.join(sa))\n",
    "        \n",
    "#     def generate_sentences(self, technique, seed, n = None, before = None, after = None) -> (list, list):\n",
    "#         \"\"\"\"\"\"\n",
    "        \n",
    "#         sentences, probs = []\n",
    "        \n",
    "#         if technique == 1:\n",
    "#             for _ in range(n):\n",
    "#                 sentence, prob = self.generate_sentence_shannon(seed, n)\n",
    "                \n",
    "#                 sentence.append(' '.join(sentence))\n",
    "#                 probs.append(prob)\n",
    "                \n",
    "#         return sentences, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlm = NetworkLM(vocab_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> to a fan and mr fogg </s>\n",
      "<s> fogg </s>\n"
     ]
    }
   ],
   "source": [
    "nlm.generate_sentence_inside_out('fogg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
